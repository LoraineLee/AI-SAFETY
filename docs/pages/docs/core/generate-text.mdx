---
title: generateText
layout:
  toc: false
---

import { Callout } from 'nextra-theme-docs';
import { OptionTable } from '@/components/table';
import { Tabs, Tab } from 'nextra-theme-docs';

# experimental_generateText

Generate a text and call tools for a given prompt using a language model.

This function does not stream the output. If you want to stream the output, use `experimental_streamText` instead.

## Parameters

The parameters are passed into `experimental_streamText` as a single options object.

- **model** - The language model to use.
- **tools** - The tools that the model can call. The model needs to support calling tools.
- **system** - A system message that will be part of the prompt.
- **prompt** - A simple text prompt. You can either use `prompt` or `messages` but not both.
- **messages** - A list of messages. You can either use `prompt` or `messages` but not both.
- **maxTokens** - Maximum number of tokens to generate.
- **temperature** - Temperature setting.
  This is a number between 0 (almost no randomness) and 1 (very random).
  It is recommended to set either `temperature` or `topP`, but not both.
- **topP** - Nucleus sampling. This is a number between 0 and 1.
  E.g. 0.1 would mean that only tokens with the top 10% probability mass are considered.
  It is recommended to set either `temperature` or `topP`, but not both.
- **presencePenalty** - Presence penalty setting.
  It affects the likelihood of the model to repeat information that is already in the prompt.
  The presence penalty is a number between -1 (increase repetition) and 1 (maximum penalty, decrease repetition).
  0 means no penalty.
- **frequencyPenalty** - Frequency penalty setting.
  It affects the likelihood of the model to repeatedly use the same words or phrases.
  The frequency penalty is a number between -1 (increase repetition) and 1 (maximum penalty, decrease repetition).
  0 means no penalty.
- **seed** - The seed (integer) to use for random sampling.
  If set and supported by the model, calls will generate deterministic results.
- **maxRetries** - Maximum number of retries. Set to 0 to disable retries. Default: 2.
- **abortSignal** - An optional abort signal that can be used to cancel the call.

## Return Type

`generateText` returns a result object wtih several properties:

- **text** - The generated text. Type: `string`.
- **toolCalls** - The tool calls that were made during the generation. Type: `ToToolCallArray<TOOLS>`.
- **toolResults** - The results of the tool calls. Type: `ToToolResultArray<TOOLS>`.
- **finishReason** - The reason why the generation finished. Type: `LanguageModelV1FinishReason`.
- **usage** - The token usage of the generated text. Type: `TokenUsage`.
- **warnings** - Warnings from the model provider (e.g., unsupported settings). Type: `string[]` (assumed type for warnings).

## Examples
