# InkeepStream

## `InkeepStream(res: Response, cb?: AIStreamCallbacks): ReadableStream` [#InkeepStream]

The `InkeepStream` function is a utility that transforms the output from [Inkeep's](https://www.inkeep.com) API into a (ReadableStream)[(ReadableStream)[https://developer.mozilla.org/docs/Web/API/ReadableStream]]. It uses [AIStream](/docs/api-reference/ai-stream) under the hood, applying a specific parser for the Inkeep's response data structure.

This works with the official Inkeep API, and it's supported in both Node.js, the [Edge Runtime](https://edge-runtime.vercel.app), and browser environments.

## Parameters

### `res: Response`

The `Response` object returned by the request to the Inkeep API.

### `cb?: InkeepAIStreamCallbacksAndOptions`

This optional parameter can be an object containing the callback functions to handle the start, each token, completion, and other events of the AI response. In the absence of this parameter, default behavior is implemented.

The `InkeepAIStreamCallbacksAndOptions` extends the standard (AIStreamCallbacks)[/docs/api-reference/ai-stream#AIStreamCallbacks] by including additional `metadata` in `onFinal` and adding an `onRecordsCited` callback.

<OptionTable
  options={[
    // ... rest of `AIStreamCallbacks`
    [
      'onRecordsCited',
      '(recordsCited: InkeepRecordsCitedData) => void',
      'An optional function that is called once for every request, after the main content of a message has completed. It includes the information about the records (sources) cited in the AI chat response.',
    ],
    [
      'onFinal',
      '(completion: string, metadata: InkeepOnFinalMetadata) => Promise<void>',
      "An optional function that is called once for every request. It's always the final callback invoked. It's passed the content of the chat response as a string and metadata as an object of type `InkeepOnFinalMetadata`.",
    ],
  ]}
/>

#### InkeepOnFinalMetadata

Information included in `metadata` of InkeepStream's `onFinal` callback.

<OptionTable
  options={[
    [
      'chat_session_id',
      'string',
      'The Inkeep chat_session_id. This is should be included in follow-up chat requests that are part of a chat session. Used for analytics and threading chat conversations.',
    ],
    [
      'records_cited.citations',
      'InkeepCitation[]',
      'Contains information about the citations used in the chat response body.',
    ],
  ]}
/>

#### InkeepCitation

Citations in the message content are formatted as, for example:

```
To get started with Inkeep, first create an account [1](https://inkeep.com).
```

The `citations` array in the `onFinal` and `onRecordsCited` callbacks contain additional information about the citations used.

<OptionTable
  options={[
    [
      'number',
      'number',
      'The number of the citation as included in the message content.',
    ],
    [
      'record',
      'InkeepRecord',
      'Information abou the record that is referenced in the citation.',
    ],
  ]}
/>

#### InkeepRecord

The `InkeepRecord` object contains information about the citation used in the message.

<OptionTable
  options={[
    ['url', 'string | null', 'The URL of the citation, if available.'],
    ['title', 'string | null', 'The title of the citation, if available.'],
    [
      'breadcrumbs',
      'string[] | null',
      'The breadcrumbs of the location of the record (e.g. `["Home", "About"]`)',
    ],
  ]}
/>

## Example

The `InkeepStream` function can be coupled with a `fetch` call to either of the Inkeep API chat endpoints:

1. `POST chat_sessions/chat_results` - To **create** a chat session
2. `POST chat_sessions/${chat_session_id}/chat_results` - To **continue** a chat session

This stream can then facilitate the real-time consumption of AI outputs as they're being generated.

Here's a step-by-step example of how to implement a combined endpoint that automatically handles both `create` and `continue` API endpoints:

```tsx filename="app/api/chat/route.ts" showLineNumbers
import {
  InkeepStream,
  InkeepOnFinalMetadata,
  StreamingTextResponse,
  experimental_StreamData,
  InkeepMessage,
} from 'ai';

// The type for the request body
interface ChatRequestBody {
  messages: Array<{
    role: 'user' | 'assistant';
    content: string;
  }>;
  chat_session_id?: string;
}

interface ChatSessionArgs {
  integration_id: string;
  chat_mode?: 'turbo' | 'auto'; // default: 'auto'
  chat_session: {
    messages: Array<InkeepMessage>;
  };
  stream?: boolean;
}

interface ContinueChatInput {
  integration_id: string;
  chat_session_id: string;
  message: InkeepMessage;
  stream?: boolean;
}

export async function POST(req: Request) {
  const chatRequestBody: ChatRequestBody = await req.json();
  const chatSessionId = chatRequestBody.chat_session_id;

  let response;
  let body;
  let url;

  if (!chatSessionId) {
    // new chat session
    const args: ChatSessionArgs = {
      integration_id: process.env.INKEEP_INTEGRATION_ID!,
      chat_session: {
        messages: chatRequestBody.messages,
      },
      stream: true,
    };
    body = JSON.stringify(args);
    url = 'https://api.inkeep.com/v0/chat_sessions/chat_results';
  } else {
    // continue chat session
    const args: ContinueChatInput = {
      integration_id: process.env.INKEEP_INTEGRATION_ID!,
      chat_session_id: chatSessionId,
      message: chatRequestBody.messages[chatRequestBody.messages.length - 1],
      stream: true,
    };
    body = JSON.stringify(args);
    url = `https://api.inkeep.com/v0/chat_sessions/${chatSessionId}/chat_results`;
  }

  response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${process.env.INKEEP_API_KEY}`,
    },
    body,
  });

  if (!response.ok) {
    throw new Error(`HTTP error! status: ${response.status}`);
  }

  // used to pass custom metadata to the client
  const data = new experimental_StreamData();

  if (!response?.body) {
    throw new Error('Response body is null');
  }

  const stream = InkeepStream(response, {
    onRecordsCited: async recordsCited => {
      // append the citations as a message annotation
      data.appendMessageAnnotation({
        recordsCited,
      });
    },
    onFinal: async (complete: string, metadata?: InkeepOnFinalMetadata) => {
      // return the chat_session_id to the client
      if (metadata) {
        data.append({ onFinalMetadata: metadata });
      }
      data.close();
    },
    experimental_streamData: true,
  });

  return new StreamingTextResponse(stream, {}, data);
}
```

This example uses the [experimental_StreamData](/docs/api-reference/stream-data) and the callback methods of `InkeepStream` to attach metadata to the response.

From [`useChat`](/docs/api-reference/use-chat), this is available as:

```tsx filename="app/chat/page.tsx" showLineNumbers
// ... your chat component

const { messages, data } = useChat();

/* For chat_session_id */

// get the onFinalMetadata item from the global chat data
const onFinalMetadataItem = data?.find(
  item =>
    typeof item === 'object' && item !== null && 'onFinalMetadata' in item,
) as { onFinalMetadata: InkeepOnFinalMetadata } | undefined;

// get the chat_session_id from the onFinalMetadata item
const chatSessionId = onFinalMetadataItem?.onFinalMetadata?.chat_session_id;

/* For messages[n].annotations, available independently for each message */

const recordsCitedAnnotation =
  messages &&
  messages.length > 0 &&
  (messages[0].annotations?.find(
    item => typeof item === 'object' && item !== null && 'recordsCited' in item,
  ) as { recordsCited: InkeepRecordsCitedData } | undefined);

// get the citations from the recordsCited annotation
const citations = recordsCitedAnnotation?.recordsCited?.citations;
```
