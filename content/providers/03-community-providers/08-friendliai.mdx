---
title: FriendliAI
description: Learn how to use the FriendliAI provider for the Vercel AI SDK.
---

# FriendliAI Provider

<Note style={{ paddingTop: 0, paddingBottom: 0 }}>
  FriendliAI is supported via OpenAI API compatibility - the OpenAI provider is
  used in the examples below.
</Note>

The [FriendliAI](https://friendli.ai/) provider contains language model support for the [Friendli Serverless Endpoints](https://friendli.ai/products/serverless-endpoints).  
It creates language model objects that can be used with the `generateText`, `streamText`, `generateObject`, and `streamObject` functions.

## Setup

The FriendliAI provider is available via the `@ai-sdk/openai` module as it is compatible with the OpenAI API.
You can install it with

<Tabs items={['pnpm', 'npm', 'yarn']}>
  <Tab>
    <Snippet text="pnpm add @ai-sdk/openai" dark />
  </Tab>
  <Tab>
    <Snippet text="npm install @ai-sdk/openai" dark />
  </Tab>
  <Tab>
    <Snippet text="yarn add @ai-sdk/openai" dark />
  </Tab>
</Tabs>

## Provider Instance

To use FriendliAI, you can create a custom provider instance with the `createOpenAI` function from `@ai-sdk/openai`:

```ts
import { createOpenAI } from '@ai-sdk/openai';

const friendliai = createOpenAI({
  baseURL: 'https://inference.friendli.ai/v1',
  apiKey: process.env.FRIENDLI_API_KEY,
});
```

[[Guide](https://docs.friendli.ai/guides/credentials)] The tokens required for model usage can be obtained from the [Friendli suite](https://suite.friendli.ai/).

## Language Models

You can create [FriendliAI models](https://docs.friendli.ai/guides/serverless_endpoints/text_generation#model-supports) using a provider instance.
The first argument is the model id, e.g. `meta-llama-3.1-8b-instruct`.

```ts
const model = friendliai('meta-llama-3.1-8b-instruct');
```

### Example

You can use FriendliAI language models to generate text with the `generateText` function:

```ts
import { createOpenAI } from '@ai-sdk/openai'
import { generateText } from 'ai'

const friendliai = createOpenAI({
  baseURL: 'https://inference.friendli.ai/v1',
  apiKey: process.env.FRIENDLI_API_KEY,
});

const { text } = await generateText({
  model: friendliai('meta-llama-3.1-8b-instruct')
  prompt: 'What is the meaning of life?',
})
```

FriendliAI language models can also be used in the `streamText`, `generateObject`, `streamObject`, and `streamUI` functions
(see [AI SDK Core](/docs/ai-sdk-core) and [AI SDK RSC](/docs/ai-sdk-rsc)).

## Model Capabilities

| Model                         | Image Input         | Object Generation   | Tool Usage          | Tool Streaming      |
| ----------------------------- | ------------------- | ------------------- | ------------------- | ------------------- |
| `meta-llama-3.1-70b-instruct` | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| `meta-llama-3.1-8b-instruct`  | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| `mixtral-8x7b-instruct-v0-1`  | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |

<Note>
  The table above only lists models of serverless endpoints. To [use more
  models](https://friendli.ai/models), send the `eid` of [Dedicated
  Endpoints](https://friendli.ai/products/dedicated-endpoints).
</Note>
