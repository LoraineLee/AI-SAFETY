---
title: FriendliAI
description: Learn how to use the FriendliAI provider for the Vercel AI SDK.
---

# FriendliAI Provider

<Note style={{ paddingTop: 0, paddingBottom: 0 }}>
  FriendliAI is supported via OpenAI API compatibility - the OpenAI provider is
  used in the examples below.
</Note>

The [FriendliAI](https://friendli.ai/) provider contains language model support for the [Friendli Serverless Endpoints](https://friendli.ai/products/serverless-endpoints).  
It creates language model objects that can be used with the `generateText`, `streamText`, `generateObject`, and `streamObject` functions.

## Setup

The FriendliAI provider is available via the `@ai-sdk/openai` module as it is compatible with the OpenAI API.
You can install it with

<Tabs items={['pnpm', 'npm', 'yarn']}>
  <Tab>
    <Snippet text="pnpm add @ai-sdk/openai" dark />
  </Tab>
  <Tab>
    <Snippet text="npm install @ai-sdk/openai" dark />
  </Tab>
  <Tab>
    <Snippet text="yarn add @ai-sdk/openai" dark />
  </Tab>
</Tabs>

## Provider Instance

### Using the OpenAI Provider

To use FriendliAI, you can create a custom provider instance with the `createOpenAI` function from `@ai-sdk/openai`:

```ts
import { createOpenAI } from '@ai-sdk/openai';

const friendliai = createOpenAI({
  baseURL: 'https://inference.friendli.ai/v1',
  apiKey: process.env.FRIENDLI_API_KEY,
});
```

### Using the `@friendliai/ai-provider` Package

You can import the default provider instance `friendliai` from `@friendliai/ai-provider`:

frist install the package

<Tabs items={['pnpm', 'npm', 'yarn']}>
  <Tab>
    <Snippet text="pnpm add @friendliai/ai-provider" dark />
  </Tab>
  <Tab>
    <Snippet text="npm install @friendliai/ai-provider" dark />
  </Tab>
  <Tab>
    <Snippet text="yarn add @friendliai/ai-provider" dark />
  </Tab>
</Tabs>

then import the provider

```ts
import { friendliai } from '@friendliai/ai-provider';
```

If you need a customized setup, you can import `createFriendliAI` from `@friendliai/ai-provider` and create a provider instance with your settings:

```ts
import { createFriendliAI } from '@friendliai/ai-provider';

const friendliai = createFriendliAI({
  baseURL: 'https://inference.friendli.ai/v1',
  apiKey: process.env.FRIENDLI_API_KEY,
  teamId: process.env.FRIENDLI_TEAM_ID || 'YOUR FRIENDLIAI TEAM ID',
});
```

### Credentials

[[Guide](https://docs.friendli.ai/guides/credentials)] The tokens required for model usage can be obtained from the [Friendli suite](https://suite.friendli.ai/).

## Language Models

You can create [FriendliAI models](https://docs.friendli.ai/guides/serverless_endpoints/text_generation#model-supports) using a provider instance.
The first argument is the model id, e.g. `meta-llama-3.1-8b-instruct`.

```ts
const model = friendliai('meta-llama-3.1-8b-instruct');
```

### Example: generating text

You can use FriendliAI language models to generate text with the `generateText` function:

```ts
import { createOpenAI } from '@ai-sdk/openai'
import { generateText } from 'ai'

const friendliai = createOpenAI({
  baseURL: 'https://inference.friendli.ai/v1',
  apiKey: process.env.FRIENDLI_API_KEY,
});

const { text } = await generateText({
  model: friendliai('meta-llama-3.1-8b-instruct')
  prompt: 'What is the meaning of life?',
})
```

### Example: Using friendli hosted tools

`@friendliai/ai-provider`를 사용하는 경우 hosted_tools 옵션을 사용할 수 있습니다.

With search grounding, the model has access to the latest information using Google search. Search grounding can e.g. be used to provide answers around current events:

```ts highlight="4,5,6"
import { friendliai } from '@friendliai/ai-provider';

const result = await streamText({
  model: friendliai('meta-llama-3.1-8b-instruct', {
    hostedTools: [{ type: 'calculator' }, { type: 'web_search' }],
  }),
  prompt: 'What is the meaning of life?',
});

for await (const textPart of result.textStream) {
  console.log(textPart);
}
```

FriendliAI language models can also be used in the `streamText`, `generateObject`, `streamObject`, and `streamUI` functions
(see [AI SDK Core](/docs/ai-sdk-core) and [AI SDK RSC](/docs/ai-sdk-rsc)).

### Model Capabilities

| Model                         | Image Input         | Object Generation   | Tool Usage          | Tool Streaming      |
| ----------------------------- | ------------------- | ------------------- | ------------------- | ------------------- |
| `meta-llama-3.1-70b-instruct` | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| `meta-llama-3.1-8b-instruct`  | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |
| `mixtral-8x7b-instruct-v0-1`  | <Cross size={18} /> | <Check size={18} /> | <Check size={18} /> | <Check size={18} /> |

<Note>
  The table above only lists models of serverless endpoints. To [use more
  models](https://friendli.ai/models), send the `eid` of [Dedicated
  Endpoints](https://friendli.ai/products/dedicated-endpoints).
</Note>
