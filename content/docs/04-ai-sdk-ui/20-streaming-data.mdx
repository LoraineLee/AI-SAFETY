---
title: Streaming Data
description: Welcome to the AI SDK documentation!
---

# Streaming Data

Depending on your use case, you may want to stream additional data alongside the model's response.
This can be achieved with [`StreamData`](/docs/reference/stream-helpers/stream-data).

## What is StreamData

The `StreamData` class allows you to stream arbitrary JSON data to the client alongside your LLM response.
This can be particularly useful in applications that need to augment AI responses with metadata, auxiliary information,
or custom data structures that are relevant to the ongoing interaction.

## How To Use StreamData

To use `StreamData`, create a `StreamData` value on the server,
append some data, and then include it in `toDataStreamResponse`.

You need to call `close()` on the `StreamData` object to ensure the data is sent to the client.
This can best be done in the `onFinish` callback of `streamText`.

On the client, the [`useChat`](/docs/reference/ai-sdk-ui/use-chat) hook returns `data`, which will contain the additional data.

### On the server

You can use `StreamData` in combination with `streamText`.
It is initialized as a separate object and you can append data to it with `append`.
Once the stream is finished, you need to call `close()` on the `StreamData` object to
ensure that the connection is closed.

```tsx
import { openai } from '@ai-sdk/openai';
import { streamText, StreamData } from 'ai';

// Allow streaming responses up to 30 seconds
export const maxDuration = 30;

export async function POST(req: Request) {
  // Extract the `messages` from the body of the request
  const { messages } = await req.json();

  // Create a new StreamData
  const data = new StreamData();

  // Append additional data
  data.append({ test: 'value' });

  // Call the language model
  const result = await streamText({
    model: openai('gpt-4-turbo'),
    onFinish() {
      data.close();
    },
    messages,
  });

  // Respond with the stream and additional StreamData
  return result.toDataStreamResponse({ data });
}
```

<Note>
  While this example uses Next.js (App Router), `StreamData` is compatible with
  any framework.
</Note>

### On the client

On the client, you can destructure `data` from the `useChat` hook which stores all `StreamData`
as a `JSONValue[]`.

```tsx
const { data } = useChat();
```

Future versions of the AI SDK will support each `Message` having a `data` object attached to it.

## Updating and Clearing Data

You can update and clear the `data` object of the `useChat` hook using the `setData` function.

```tsx
const { setData } = useChat();

// clear existing data
setData(undefined);

// set new data
setData([{ test: 'value' }]);

// transform existing data, e.g. adding additional values:
setData(currentData => [...currentData, { test: 'value' }]);
```

#### Example: Clear on Submit

```tsx highlight="18-21"
'use client';

import { Message, useChat } from 'ai/react';

export default function Chat() {
  const { messages, input, handleInputChange, handleSubmit, data, setData } =
    useChat();

  return (
    <>
      {data && <pre>{JSON.stringify(data, null, 2)}</pre>}

      {messages?.map((m: Message) => (
        <div key={m.id}>{`${m.role}: ${m.content}`}</div>
      ))}

      <form
        onSubmit={e => {
          setData(undefined); // clear stream data
          handleSubmit(e);
        }}
      >
        <input value={input} onChange={handleInputChange} />
      </form>
    </>
  );
}
```
